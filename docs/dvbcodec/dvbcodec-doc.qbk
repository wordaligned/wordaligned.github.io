[article A Mini-Project to Decode a Mini-Language
    [version 1.0]
    [authors [Guest, Thomas]]
    [copyright 2004 Thomas Guest]
]

[/ Some links]

[def __title__     a_mini_project_to_decode_a_mini_language]
[def __boost__     [@http://www.boost.org/ Boost]]
[def __dvb__       [@http://www.dvb.org DVB]]
[def __homepage__  [@http://www.wordaligned.org homepage]]
[def __mpeg2__     [@http://www.chiariglione.org/mpeg/standards/mpeg-2/mpeg-2.htm MPEG-2]]
[def __perl__      [@http://www.perl.org Perl]]
[def __python__    [@http://www.python.org Python]]
[def __raymond__   [link refs.raymond Raymond]]
[def __spirit__    [@http://spirit.sourceforge.net Spirit]]
[def __gnu__       [@http://www.gnu.org ['GNU]]]
[def __info__      [$images/info.png]]

[section Introduction]
This article appears in two parts. 

[link part_one.motivation Part One] describes the first stages of a miniproject to
write a codec for a minilanguage. (If you don't know what codecs and
minilanguages are, don't worry. Read on!)

[link part_two.introduction Part Two] describes the later stages of this project and
presents an actual first implementation of the codec.

[link part_three.introduction Part Three] describes the inevitable refactor and
the delivery of version 1.0 of the codec.

[endsect] [/ End of Intro]

[section Part One]

[h2 Motivation]

The motivation for this article comes from ['The Art of UNIX Programming] by
[link refs.raymond Eric S. Raymond]. This is one of the most inspiring books I've read on
how to write software: although firmly rooted in the traditions of the /UNIX/
operating system, the culture and philosophy it describes applies far more
widely. It has reinforced my belief that software development can indeed be an
art.

Having read this book, wanted to put some of its ideas into
practice. So I set myself a mini-project.

[h2 An Idea for a Mini-Project]

As a starting point, I'd like to summarise two of [link refs.raymond Raymond's] 
most important lessons.

* Data structures, not algorithms, are central to programming.

* Prefer text file formats: they're human-readable and extensible. If you must
use a binary format then invest in a tool which converts from this format to a
textual one and back again. This will facilitate working with your data.

I work in a domain where the need for compression requires the use of binary
file formats: namely digital television (DTV). Digital video is typically
__mpeg2__ encoded. This is a highly compressed encoding designed to squeeze as
much content as possible into a limited bandwidth. __mpeg2__ encoding also allows
video and audio content to be combined with metadata: for example, a
television programme might be accompanied by a text description of itself and
of what's showing next.

[blurb __info__ The proper term for these particular items of metadata is Event
Information, present and following. Since this article is not primarily about
digital television I shall avoid such jargon as far as possible.]


To get to grips with this metadata a conversion tool is required. The specific
task I set myself, then, was to write a tool to convert __mpeg2__ metadata from
binary to text, and, if required, to reverse the process. Such an encode/decode
tool is commonly referred to as a /codec/.


My project, then, was to implement a digital television codec.


[h2 The MPEG-2 Bit Stream Syntax: An Example of a Minilanguage]

The metadata format is specified using the __mpeg2__ bit stream syntax which
is defined in [link refs.iso_iec_13818_1 ISO/IEC 13818-1]. Data items are
described by name and length in bits using a C-like procedural syntax. An
example makes this clear:

[pre
   program_map_section() {            
       table_id                        8 
       section_syntax_indicator        1 
       '0'                             1 
       reserved                        2 
       section_length                 12 
       program_number                 16 
       reserved                        2  
       version_number                  5 
       current_next_indicator          1  
       section_number                  8 
       last_section_number             8 
       reserved                        3  
       PCR_PID                        13 
       reserved                        4  
       program_info_length            12 
       for (i=0; i<N; i++) {             
           descriptor()                  
       }                                 
       for (i=0;i<N1;i++) {              
           stream_type                 8 
           reserved                    3  
           elementary_PID             13 
           reserved                    4  
           ES_info_length             12 
           for (i=0; i<N2; i++) {        
               descriptor()              
           }                             
       }                                 
       CRC_32                         32
   }                                     
]

What we have here is the bit stream syntax for a section of the `Program Map
Table`. The first 8 bits give the table id (which happens to be 2, for this
particular table); the single bit which follows provides the section syntax
indicator; the next bit is always set to zero; the next two bits are reserved
(and should each be set to one); and so on, until we get to the 32 bit CRC.

[blurb __info__ I assume the /reserved/ parts of the section are included to provide
room for a degree of future extensibility. But not much room. This is one of
the reasons why __raymond__ advocates text file formats: ['if you need a larger
value in a text format, just write it.]]

To provide a little context: the `Program Map Table (PMT)` supplies basic
information about the digital television services present in an __mpeg2__
transport stream. A section of this table -- as shown above -- defines the
elementary streams which comprise a single television service. For example,
the `PMT` for the BBC1 digital television service consists of a video stream,
an audio stream, a subtitle stream and some data streams. Of course, 
[link refs.iso_iec_13818_1 ISO/IEC 13818-1] defines the format of many other tables and
sections, and related specifications -- such as [link refs.etsi_en_300_468 EN 300468]
define many more.

This textual specification of a binary format is an example of what
__raymond__ terms a mini-language. In fact we have a Turing-complete
mini-language: that is, it allows for loops and conditionals. The particular
example shown here does not include any conditionals, though we do have nested
loops. Note also the referenced `descriptor()` items. To fully parse the
`program_map_section()` we'll need the `descriptor()`
format specified too:

[pre
   descriptor() {              
       descriptor_tag         8
       descriptor_length      8
       for (i=0; i<N; i++) {   
            private_data_byte 8
       }                       
   }                           
]

[h2 Complications]

The syntax is easy to read, particularly to anyone familiar with C. However,
if we look more closely at the for-loop in the `descriptor`, although it's
apparent that `i` must be an integral loop counter, it's less clear where `N`
is defined. Similarly, in the `program_map_section`, how do we find the
values of `N1` and `N2`?


[link refs.iso_iec_13818_1 ISO/IEC 13818-1] answers these questions. In the `descriptor`, the
`descriptor_length` data element encodes an unsigned integer which tells us
how many bytes of data are to follow: so `N` is simply the value obtained by
decoding `descriptor_length`. The `program_map_section` is not quite so simple. `N` is easy
enough -- it's as many variable-length descriptors as it takes to fill the
total length specified by `program_info_length`. `N2` is similarly the
number of descriptors to fill the length specified by the most recent
occurrence of `ES_info_length`. For `N1`, however, we have to keep decoding
elementary streams until the following is true:

[pre
     Sum of elementary stream lengths (in bytes)
     ==  section_length - 
         - (2 + 5 + 1 + 8 + 8 
            + 3 + 13 + 4 + 12) / 8
         - program_info_length
         - 32 / 8
]

We have to divide by 8 since field widths of values within the PMT section are
given in bits -- but length fields give values in bytes.

Despite these complications, the encoding is well-designed: we can parse these
binary data structures sequentially without needing to look ahead; and we can skip
over any bits we're not interested in.

In fact, the more closely we inspect our examples, the more we notice. This
is good. Recall that data structures, not algorithms, are central to
programming. Already we're getting stuck into the data.

While we're in this positive frame of mind, let's review the full range of
control structures required by the [link refs.iso_iec_13818_1 ISO/IEC 13818-1]
bitstream syntax:

[h2 ISO/IEC 13818-1 Control Structures]

[pre
    while (condition) { 
        data_element
        ...
    }   

    do {
        data_element
        ... 
    }
    while (condition)


    if (condition) {
        data_element
        ...
    }
    else {
        data_element
        ...
    }
    
    for (i=0;i<n;i++) {
        data_element
        ...
    }
]

So, we've got pretty much C's control structures, excepting `switch`,
`break`, `return` and `continue`.

This is starting to look alarming. How complex can a `condition` be? How shall
we handle three different looping constructs? Our mini-project has become rather
bigger than we imagined.


[h2 Back to the Data]

The thing to do at this point is to shelve these concerns and get back to
specifics. So, I got hold of some PMT section data and parsed it by hand. I
used two types of data:

* PMT sections pulled out of recorded digital TV broadcasts
* a simple PMT section synthesised by hand.

I shall spare you the details. Note though that in parsing by hand we're
already starting work on our text output format. For example, given the binary
contents of a synthesised descriptor:

[pre
    0a 04 0a 0b 0a 0b]

and recalling the descriptor syntax:

[pre
    descriptor() {              
        descriptor_tag         8
        descriptor_length      8
        for (i=0; i<N; i++) {   
             private_data_byte 8
        }                       
    }                           ]

a suitable output might be:

[pre
    descriptor() {              
        descriptor_tag         8 = 0x0a
        descriptor_length      8 = 0x04
        for (i=0; i<N; i++) {   
             private_data_byte 8 = 0x0a
             private_data_byte 8 = 0x0b
             private_data_byte 8 = 0x0a
             private_data_byte 8 = 0x0b
        }                       
    }
]


I have deliberately chosen an output format which closely resembles the syntax
definition. The loop has been unrolled, but I have retained the loop control
to indicate the structure and origin of the data. I have chosen a hexadecimal
representation for the data values -- always a good choice for binary data --
and explicitly indicate the numeric base used by prefixing these values with the
string `0x`. Finally, I have retained the bit widths for convenience: this
will mean that when converting from text to binary, there will be no need to
refer back to the descriptor syntax. 

Referrring back to our motivating reference, we see we have instinctively
followed one of __raymond__'s recommendations:

[:When filtering, never throw away information you don't need to.]

Here, the term /filter/ is used in its /Unix/ sense, and applies well to a
codec; and the reasoning is that any discarded information can never be used
in any program further down the /Unix/ pipeline. In our example, we can see
that the output includes all the information carried by both the descriptor
syntax definition and by the example descriptor.


[h2 Handling Failures]

Suppose our descriptor was too short:

[pre
    0a 04 0a 0b 0a
]
        
What should our codec make of such data?

Maybe something like this:

[pre
   descriptor() {              
       descriptor_tag         8 = 0x0a
       descriptor_length      8 = 0x04
       for (i=0; i<N; i++) {   
            private_data_byte 8 = 0x0a
            private_data_byte 8 = 0x0b
            private_data_byte 8 = 0x0a 
   [*>>> ERROR: end of data reached. descriptor() incomplete.]
]

It's perhaps premature to tie down how errors should be handled, other than to
say that they should draw attention to themselves, that they shouldn't crash
the codec, and that they should provide useful diagnostics.  But it certainly
isn't premature to include some malformed data in our test set.

Another point __raymond__ makes about data conversion tools is that they should
be generous in what they accept (as input) but rigorous in what they emit (as
output). In our case, this means that a user might change the layout of a text
version of a`descriptor` to read like this:

[pre
    descriptor() 
    {   
        descriptor_tag 8 = 0xA
        descriptor_length 8 = 0x4
        for (i = 0; i < N; i++) 
        {    
             private_data_byte 8 = 0xA
             private_data_byte 8 = 0xB
             private_data_byte 8 = 0xA
             private_data_byte 8 = 0xB
        }                       
    }                           
]

and still expect the codec to convert this to binary as:

[pre
    0a 04 0a 0b 0a 0b
]

One of the great benefits of having a codec is that we can generate binary
data from an easy-to-edit textual form: it would be a severe limitation if
the encoding process was over-sensitive about whitespace, layout, or the
capitalisation of hexadecimal numbers.


[h2 Reducing Project Scope]

Whilst tinkering around with my test data set, I've also been paging through
the __mpeg2__ bitstream syntax. The bad news is that the expressions which appear
in conditionals may be quite complex, making use of all the usual C
arithmetic, bitwise, logical and relational operators as well as a few
domain-specific additions.

The good news is that we can make good progress if we restrict our
scope as follows:

* restrict the control structures to `for() {...}` and 
      `if (condition) {...} else {...}`
      
* restrict conditions to the form `field == value`

These restrictions will not make a lot of sense to end users. In end user
terms, we can aim for a first release of our codec which will only support
sections from the following four tables:

* Program Association Table (PAT)
* Conditional Access Table (CAT)
* Network Information Table (NIT)
* Program Map Table (PMT)

This reduced scope may seem rather limiting. Note however that these
four tables -- collectively termed the ['Program Specific Information
(PSI) Tables] -- ['contain the necessary and sufficient information to
demultiplex and present programs] ([link refs.iso_iec_13818_1 ISO
13818-1]). Note further that our syntactic restrictions will not stop
us from extending our codec to handle the complete set of __dvb__
[link refs.etsi_en_300_468 Service Information (SI) tables], which
contain just about all of the metadata used in European digital
broadcasts.  Note finally that we remain faithful to our aims:
__raymond__ emphasises the need to release early and often, so that
users can drive (and implement, even, in an open source world) future
developments. By reducing scope, we allow for this early feedback. We
must take care, though, to follow another Unix maxim, and keep our
design extensible.


[h2 A Prototype Descriptor Decoder]

    /**
     * @brief Decode a descriptor.
     * @param begin The start of the descriptor data
     * @param end One past the end of the descriptor data
     * @param out Output stream for the decoded data
     */
    bool 
    decodeDescriptor(desc_iter begin, desc_iter end, std::ostream & out)
    {
        out << "descriptor() {\n";
    
        if (begin != end) {
            out << "    descriptor_tag 8 = "
                << *begin++ << "\n";
        }
       
        // We don't know yet how much data we need to decode.
        // Use a special non-zero value to indicate this.
        unsigned int to_decode = 0xff;
       
        if (begin != end) {
            to_decode = *begin++;
            
            out << "    descriptor_length 8 = "
                << to_decode << "\n";
                
            out << "    for(i=0; i<N; i++) {\n";
           
            while (begin != end && to_decode != 0) {
                out << "        "
                    << "private_data_byte 8 = "
                    << *begin++ << "\n";
                --to_decode;
            }
            out << "    }\n"; 
        }
       
        if (begin != end) {
            out << "ERROR: descriptor() too long.\n";
        } else if (to_decode != 0) {
            out << "ERROR: end of data reached. "
                << "descriptor() incomplete.\n";
        } else {
            out << "}\n"; 
        }

        return begin == end && to_decode == 0;
    }

The function above is a direct first attempt at writing a descriptor decoder.
Whilst there may be some mileage in this approach, some weaknesses are
apparent:

* The indentation is fixed. This won't do if we are decoding a descriptor
     in the broader context of a PMT section, when it can appear at two different
     levels.
     
* The error handling is clumsy.
   
* Data -- in this case, the descriptor's syntax -- has become muddled with
     control flow. 
     
Now is not the time to deal with these weaknesses. We shall simply note that
the first is simple to fix and the second can easily be improved on. It's the
third weakness which, in the longer term, will lead to code which is harder to
understand, maintain and extend. On the other hand, this function demonstrably
works on our test data set, which is encouraging; and it's not hard to see how
the approach taken could be extended to decode PAT, CAT, NIT and PMT sections
-- which is all we've decided to do.

[h2 Design Alternatives]

We are now in a good position to consider the design of our dtv-codec. Three
alternatives spring to mind:

* Implement a descriptor-codec, a pmt-codec, and so on as required. Here,
      each mini-codec understands its own designated part of the syntax.
      Then the dtv-codec simply farms out work as appropriate.  This extends the
      direct approach described above.

* Implement a general dtv-codec which understands the full bitstream
      syntax and can use it to parse an arbitrary section format. All that
      then remains is to prime this codec with the required section
      formats.

* Devise a code generator which, given a section format, will generate a
      program to code/decode that particular format.
  
All three alternatives are good, and all seem in line with our motivating
aims. The third, in particular, exemplifies __raymond__'s:

[:['Rule of Generation:
Avoid hand-hacking; write programs to write programs when you can.]]

In chosing which route to take, we should remember the [link refs.xp XP]
mantra: ['Do the simplest thing possible]; which, in UNIX-speak, becomes the
more prosaic: ['Keep it Simple, Stupid!]


[h2 More Details]

For those who want to implement their own codec, you can find a link
zip archive [link downloads.test_suite here]. This archive contains:

* binary PAT, CAT, NIT and PMT sections
* synthesised text sections
* alternative text versions
* malformed binary sections 
* the relevant section syntax definitions
* table_id values
* a README

For those who'd prefer to see my attempt; proceed to 
[link part_two.introduction part two] of this article.


[h2 Conclusions]

Progress has been made, and without the need to compromise our artistic
aims.  Even before we've completed the project, we've started to receive the
main benefit: of understanding our data.

The second part of this article is where we compromise, get our hands
dirty, bite off more than we can chew -- that is, we write some code.

 
[endsect] [/ End of Part one]

[section Part Two]

[h2 Introduction]

This article appears in two parts. Part one described the preliminary
stages of a miniproject to write a codec for a minilanguage, delivering:

* a rough specification of the codec,
* a suite of test data,
* some prototype code,
* three implementation strategies.
    
Part two -- this part -- continues the project and presents the final
implementation.


[h2 Motivation]

[link part_one.motivation Part one] of this article drew inspiration
from ['The Art of UNIX Programming], by [link refs.raymond Eric S. Raymond]. 
Part two continues to draw from this same source,
which applies as readily to implementation as it did to design.

At this point, I can reveal a second motivating source, ['The Tale of a
Struggling Template Programmer], by [link refs.heinzmann Stephan Heinzmann],
which served to remind me how frustrating software development can be:
sometimes the tools are to blame, sometimes the languages appear faulty, and
sometimes the poor programmer takes a wrong turn. On a more personal note, it
reminded me that I ought to experiment with modern C++.

[blurb __info__ My job involves writing portable C++ to run on
embedded platforms. The compilers supplied for these platforms often
do not support "modern" C++ features such as templates.]

Anyone familiar with both sources will appreciate there's a degree of tension
between them. In what follows, I document my attempts to resolve this tension.
Along the way, we shall revisit the world of __mpeg2__ video encoding and get
started with the __boost__ __spirit__ library.


[h2 Project Recap]

To briefly recap, then, our goal is to write a tool to convert the binary
format used in __mpeg2__ digital video broadcasting into a textual form and back
again -- to write a `dvbcodec`. For example, we would like to convert a
section of the Program Association Table (PAT), whose syntax is as follows:

[#program_association_section]
[pre
    program_association_section() {
        table_id                   8
        section_syntax_indicator   1
        '0'                        1
        reserved                   2
        section_length            12
        transport_stream_id       16
        reserved                   2
        version_number             5
        current_next_indicator     1
        section_number             8
        last_section_number        8
        for (i=0; i<N;i++) {
            program_number        16
            reserved               3
            if(program_number == '0') {
                network_PID       13
            }
            else {
                program_map_PID   13
            }
        }
        CRC_32                    32
    }
]

The numerical values here represent field widths in bits: the first byte of
the section encodes the `table_id`, the next bit the
`section_syntax_indicator`, and so on until the final four bytes which encode
the cyclic redundancy check.

The PAT is just one of the tables we would like to decode. There are many
others, the next three most important being the the Conditional Access Table,
the Program Map Table and the Network Information Table (CAT, PMT and NIT).

The textual output format we decided on should reflect the syntax description
as follows:

[pre
    program_association_section() {
        table_id                   8 = 0x0
        section_syntax_indicator   1 = 0x1
        '0'                        1 = 0x0
        ...
        CRC_32                    32 = 0xcae52d9f
    }
]

[#implementation_strategies] We came up with three possible
implementation strategies for our `dvbcodec`:

* Implement a pat-codec. Then implement a cat-codec, then a pmt-codec, etc.

* Implement a general codec which understands the full bitstream syntax and
can use it to parse an arbitrary section format. All that then remains is to
prime this codec with the required section formats.

* Devise a code generator which, given a section format, will generate a
program to encode/decode that particular format.


[h2 Towards a Solution]

The first strategy holds little appeal: it risks being a recipe for
cut-and-paste code and boring repetition. We reject it.

The second and third strategies look to have more going from them,
particularly since we have restricted our scope to a subset of the full
bitstream syntax. Although these strategies appear rather different, they both
require us to parse syntax descriptions of the general form exemplified by the
`program_association_section`.

So, we need a parser. We need one capable of handling conditionals and loops:
one capable, that is, of handling a Turing-complete minilanguage. __raymond__
can advise. In general terms, he suggests:

* Where possible, reuse. Look for a proven, documented, supported, portable,
parser. (He argues these criteria pretty much imply an open source solution.)
      
* Prefer scripting languages such as __python__ and __perl__. These facilitate
rapid development and are less prone to memory management bugs. You may
not need the raw performance offered by `C/C++`, and the library support
offered by these languages is often superior.

On the more specific subject of parsers, __raymond__ recommends `lex` and `yacc`
though, in keeping with the Unix philosophy of documenting weaknesses, he
admits these tools are not perfect. He also suggests:

[:['If you can implement your parser in a higher-level language than C (which
we recommend you do ...) then look for equivalent facilities like
[@http://www.python.org Python's] [link refs.ply PLY] ...]]

I tend to agree with __raymond__ but I'm not convinced [link refs.ply PLY] is
the way to go here. Of course, it won't get me very far with my aim of finding
out about modern C++, but it's also not part of the standard __python__
distribution. In fact, a web search reveals several other __python__ parser
frameworks -- it's unclear which will prevail.

The C++ standard library doesn't provide a parser either. We might make some
progress tokenising our data with `std::strtok` or even `std::sscanf`,
but this won't suffice. `Lex` and `yacc` are of course a time-tested
combination, but I'd rather not have to learn two more minilanguages.

The next place to look is in the next best thing to the C++ standard
library, namely __boost__. Three clicks from the [@http://www.boost.org front
page] takes us to the Spirit parser, which claims to be a scalable parser
framework written in C++. We trust the source, the
[@http://www.boost.org/libs/spirit/index.html documentation] is good, the
examples work first time: let's try some code.


[h2 Getting Started with __spirit__]

The code below is a complete program to recognise lines of the form: 

[pre
   reserved 2 = 0x3
]

this being the format we arrived at for fields of our text sections.

    #include <boost/spirit/core.hpp>
    #include <iostream>
    #include <string>
    
    using namespace boost;
    
    /**
     * @brief Parse a string representing a field 
     * @returns True if the field matches the format:
     * <field_name> <bitwidth> = <value>, false otherwise.
     */
    bool
    parseField(std::string const & str) {
        return spirit::parse(
             str.begin(), 
             str.end(),
             
             spirit::lexeme_d[+spirit::graph_p]
             >>   spirit::uint_p
             >>   '='
             >>   spirit::hex_p,
             
             spirit::space_p).full;
    }
    
    int main() {
    
        std::cout
            << "Enter text.\n"
            << "Lines will be matched against: \n"
            << "<field_name> <bitwidth> = <hexvalue>\n"
            << "Type 'q' to quit\n";
        
        std::string str;
        std::string const quit("q");
    
        while (std::getline(std::cin, str) &&
               str != quit) {
            std::cout 
                << (parseField(str) ? "hit" : "miss")
                << std::endl;
        }
        return 0;
    }
    
Here, the action is concentrated in the function `parseField()`, which
wraps a call to `spirit::parse()`. `spirit::parse()` accepts as arguments:
    
* two iterators marking the start and end of the data to be parsed,
       
* a parser,
       
* a skip parser.
       
We have used `spirit::space_p` directly as our skip parser. This primitive
parser recognizes whitespace and tells `spirit::parse()` which characters it
should skip past in the input. A more sophisticated skip parser might be used
to skip comments.
    
[h2 Operator Overloading]

The parser itself is a sequence of sub-parsers which can be read: recognise
input consisting of a block one or more printable characters, followed by an
unsigned integer, followed by the equals sign, followed by a hexadecimal
integer.

Operator overloading is used by __spirit__ to make such expressions into readable
approximations of EBNF syntax descriptions (see also [link refs.antonsen Antonsen] for more on
this technique). Here, we see that `operator<<()` has been overloaded as a
sequencing operator, `prefix operator+()` has been overloaded to mean "one or
more of", and `operator[]()` is overloaded to adapt the behaviour of a
sub-parser -- in this case using `spirit::lexeme_d` to turn off whitespace
skipping.


[h2 Parser Generators]

I should also mention that the `'='` sub-parser is a shorthand for
`spirit::ch_p('=')`, which in turn is a parser generator 
returning the character literal parser `spirit::chlit<char>('=')`.

Similarly, `spirit::hex_p` and `spirit::uint_p` are parser generator functions
which return suitable specialisations of the `spirit::uint_parser` template
struct.  The full template parameters of this struct are as follows:

    template <
        typename T = unsigned,
        int Radix = 10,
        unsigned MinDigits = 1,
        int MaxDigits = -1>
    struct uint_parser { /* */ };

The helper functions `hex_p` and `uint_p` are often good enough, but it's also
useful to have the full flexibility of the base parser. For example, if we
need to match larger hex values, and `long long` is available, we could create
an alternative hex parser:

    uint_parser<unsigned long long, 16> const
        long_long_hex_p   
            = uint_parser<unsigned long long, 16>();

In fact, the `uint_parser` should work with any user defined scalar type.

(You've probably noticed I'm now working in the `boost::spirit` namespace. I
continue to do so for the remainder of this article.)

One thing I cannot do with the hex parser, unfortunately, is get it to accept
the `0x` we've used to prefix hex digits. We can fix the bug
in our program by introducing a new parser rule.

    with_base_hex_p
        =   lexeme_d
            [
                as_lower_d["0x"]
                >>  hex_p
            ];

Note here:

* the `as_lower_d` directive, which converts all characters from the input
      to lowercase, and therefore recognising both `0x` and `0X`.
      
* the rather unusual code layout. I have tried to follow the
[@http://www.boost.org/libs/spirit/doc/style_guide.html Spirit style
guide] when writing parser grammars.  This will become
increasingly more important when we develop a more substantial grammar.
      
* the string literal `"0x"`, which in this context becomes yet another parser.


[h2 Semantic Actions]

Simply recognising fields is not enough: we need to act on their contents.
That is, we must associate semantic actions with the sub-parsers. This can be
done using another overload of `operator[]()`, which enables us to link an
action to a parser.

Here, then, is an encoder which will convert text versions of sections to
binary. I have omitted `#include` directives etc. for brevity. The full
implementation is available with the [link downloads.introduction source distribution] for
this article.

    typedef std::string::const_iterator iter;
    
    /**
     * @brief Put the input value to the output stream 
     * using the specified bitwidth
     */
    void
    putBits(std::ostream &, unsigned w, unsigned v)
    { /* */ }
    
    /**
     * @brief Parse a field of the form:
     * <field_name> <bitwidth> = <value>
     */
    bool
    parseField(iter const & begin, iter const & end,
               unsigned & bitwidth, unsigned & value) {
        return parse(
             begin, 
             end,
             
             lexeme_d[+graph_p]
             >>   uint_p[assign_a(bitwidth)]
             >>   '='
             >>   lexeme_d
                  [
                      ! as_lower_d["0x"]
                      >>  hex_p[assign_a(value)]
                  ]
             ,
             
             space_p).full;
    }
    
    int main() {
        std::string str;
        int line = 0;
        try {
            while (std::getline(std::cin, str)) {
                ++line;
                unsigned bitwidth, value;
                
                if (parseField(str.begin(), str.end(), 
                               bitwidth, value)) {
                    putBits(std::cout, 
                            bitwidth,
                            value);
                }
            }
        }    
        catch (std::exception & exc) {
            std::cerr 
                << "Error parsing line " << line 
                << "\n" << str << "\n"
                << exc.what() << std::endl;
            return -1;
        }
        return 0;
    }

Note here:

* I have used typedefs for the iterators passed into the parser. This will
ease switching to another forward iterator type, if required.
      
* I decided to make the `0x` preceding hexadecimal values optional, using
__spirit__'s overload of `operator!()`

* The use of the `assign_a` actor for our semantic action. We could have used
any function accepting an unsigned integer or any functor providing
`operator()(unsigned int) const`. Again, it's simpler to use one of __spirit__'s
off-the-peg actors.

* The program implements a classic `Unix` filter. This makes it suitable for
use in a `Unix` pipeline. See __raymond__ for more on this. Unfortunately, I'm
not sure this is a great idea for binary output: I haven't found a portable
way to reset `std::cout` to binary mode.


[h2 Exceptions in Parsers]

Another important point to note about our simple encoder is the way it handles
failure conditions using C++ exceptions rather than C-style error codes.
There are plenty of failure conditions to handle: a value might not fit in the
available bitwidth, the output stream might not be in a suitable state, and so
on.

In this simple parser we might equally well have passed error codes around,
but a more complex parser is likely to involve recursion and/or nested
function calls. Exceptions perform well in both the simple and the complex case,
offering a scalable solution.

The __spirit__ parser framework itself uses exceptions internally for similar
reasons. To quote the [@http://www.boost.org/libs/spirit/index.html documentation]:

[:['C++'s exception handling mechanism is a perfect match for Spirit due to
its highly recursive functional nature. C++ exceptions are used extensively
by this module for handling errors.]]

Like our program, __spirit__ should not leak any such exceptions to its users.


[h2 Weaknesses]

The simple encoder presented above follows [refs.postel Postel's prescription],
to a degree . It doesn't mind too much about whitespace; it allows any
sequence of printable characters as a field name; and it isn't fussy about the
presentation of hexadecimal numbers.

Its main flaw is that it does not look at the text format of our sections as a
whole: it simply skips the lines which close blocks or start loops, for
example. This means the encoding will quietly do the wrong thing given input
where a new-line has gone missing, or where the data has been truncated. This
is dangerous. It also means the encoder cannot check the integrity of our text
data -- for example, to confirm the `section_length` field contains the actual
section length, or to validate a CRC.

When we start thinking along these lines, we realise that perhaps the encoder
should calculate the values of these fields for us. We'll need a CRC generator
anyway -- why not embed it in the encoder?

These are important points. However, we never considered data validation when
we planned our codec and I'm not going to worry about it just yet -- I need to
get started on the decoder. Data validation, though valuable, would need to be
optional since an encoder must let us generate broken data for test purposes.
Also, __raymond__ encourages us to limit options whenever possible: if we can
release code earlier then our users can tell us which options they really
want. Ideally, he suggests we make the release open source, and allow users to
(submit patches which) implement these options.


[h2 Progress Review]

We've used __spirit__ to write a micro-parser to drive the encoder. We're ready to
start on the decoder. __spirit__'s scalability will be tested.


[h2 The Decoder]

I decided to attempt the second implementation strategy: to develop a codec
which understands the bitstream syntax and can use it to parse an arbitrary
section format. I had no good reason for preferring this to the code-generator
strategy.

As already noted, this is a parsing task. We will use __spirit__ to define the
grammar used by the bitstream syntax. We can then parse our static program
data -- the section formats we're interested in -- which gives us the
basis we need to parse the run-time program inputs, that is, actual
instances of binary encoded sections.

[h2 Grammar Definitions and Parse Trees]

I do not propose to dwell on the practical use of __spirit__ for much longer:
we've already seen enough of what it can do, so for full implementation
details please refer to __spirit__ and the codec [link downloads.introduction source
distribution].

For the decoder, note that simply parsing the data once and associating
semantic actions to the various lexical elements is not enough. For instance,
to process descriptor loops we need to revisit the same parser node several
times. __spirit__ provides abstract syntax trees for exactly this purpose.

I do think it is worth presenting here a portion of the section grammar. To
me, this is a quite remarkable application of C++. For even more remarkable
transcriptions of EBNF syntax definitions into Spirit grammars -- including a
C++ tokenizer and a C parser -- I recommend a visit to the 
[@http://spirit.sourceforge.net/repository/applications/show_contents.php Spirit
Applications Repository].

    /**
     * @brief MPEG-2 Section grammar defined using Boost Spirit.
     *
     * Reference:
     *   - ISO/IEC 13818-1, MPEG-2 Transport Stream
     */
    struct Section :
        public boost::spirit::grammar<Section>
    {
        template <typename ScannerT>
        struct definition
        {
            definition(Section const & /*self*/)
            {
                section_
                    =   section_ref_
                        >> section_body_
                    ;
    
                section_ref_
                    =   text_id_
                        >>   '('
                        >>   ')'
                    ;
            
                text_id_
                    =   leaf_node_d[
                            lexeme_d[
                                alpha_p
                                >> * (alnum_p | '_')
                                ]
                            ]
                    ;
    
                quoted_binary_
                    =   leaf_node_d[
                            lexeme_d[    
                                '\''
                                >>  bin_p
                                >> '\''
                            ]
                        ]
                    ;
                
                section_body_
                    =   ch_p('{')
                        >> *(       field_
                                |   loop_
                                |   conditional_
                                |   section_ref_
                            )
                        >> '}'
                    ;
                
                field_
                    =   identifier_
                        >>   uint_p
                    ;
    
                identifier_
                    =   text_id_
                        |   quoted_binary_
                    ;
    
                conditional_
                    =   str_p("if")
                        >> condition_
                        >> section_body_
                        >>  ! (str_p("else")
                               >>   section_body_)
                    ;
    
                condition_
                    =   inner_node_d['('
                            >> text_id_
                            >> "=="
                            >> quoted_binary_
                            >> ')'
                            ]
                    ;
    
                loop_
                    =   loop_control_
                        >> section_body_
                    ;
    
                loop_control_
                    =   leaf_node_d[str_p("for")
                        >>   '('
                        >>   * (anychar_p - ')')
                        >>   ')'
                        ]
                    ;
    
            }
            
            ...
            
            boost::spirit::rule<ScannerT> const &
            start() const
            {
                return section_;
            }
        };
    };
    
    
[h2 Decisions Taken]
    
Many of the decisions taken when writing our naive encoder scale up to the
decoder: limited options; exceptions used in preference to error codes; __spirit__
style guide for grammar definitions; typedefs for iterators.
    
Some decisions were ones we haven't yet faced. The main one was: where should
we put section format definitions (for the PAT, CAT, PMT and NIT)? There are
two obvious alternatives:
    
* create a C++ source file containing these definitions -- perhaps as an array
of string literals,
          
* place them in a text file in a known location, and have this file read when
the decoder starts up.
    
The second alternative is perhaps most faithful to our original aims. Program
logic and program data are nicely separated, and extending the decoder to
handle other sections is a simple matter of editing the text file. No
recompilation necessary.

Despite these attractions, I went for the first option -- partly because it's
easier to implement and partly because I didn't want to work out where to put
the text file.

The other corner I cut concerns determining how and when to exit loops. The
issue is fully described in the first part of this article (see the subsection
headed [link part_one.complications Complications]. My resolution was to
notice that loops always exit when we've used up the number of bytes encoded
in a `length` field -- with the single exception of the outermost loop, which
may end four bytes early in order to leave space for a CRC. So, the decoder
maintains a stack of `length` fields, testing the top value after each loop
iteration, popping it on loop exit. The first item to be stacked may need
adjusting to allow for the four byte CRC. Again, the [link downloads.introduction source
distribution] should make this clear.

I could find no official statement regarding what could be used as a field
name in the section format definitions: inspection suggested that these names
were rather similar to C identifiers, with the important addition of quoted
binary values for fixed fields (e.g. the `'0'` which is the third named field in
the `program_association_section` format definition).

A few more parse tree node directives might have resulted in a leaner decoder,
but I wanted the syntax grammar to be as simple as possible. I am
inexperienced in writing grammars and preferred a small amount of extra code
in my application. The application is quite compact anyway.

[#ship_happens]
[h2 [link refs.alexandrescu Ship Happens]]

__raymond__ has lots of practical advice on how to ship a source code
distribution, going down to details of file naming conventions. Some of the
suggestions I have followed are:

* choose a suitable license

* include a `README`

* set up a project homepage

* include a `BUGS` file, listing known defects and limitations

* include platform/compiler details

* include self-test code
    
The `BUGS` file is a strangely satisfying thing to write, particularly if
you've ever delivered software which doesn't admit to defects, let alone
limitations (or indeed if you've ever used such software). In this case it is
essential to document both.

Version 0.1 of the `dvbcodec` features the naive encoder described in the
preceding -- really only of use for system testing (we can check that
decoding then encoding a file recreates the original file). The decoder is
rather better -- in fact, I've extended it beyond the original specification
to handle a few more section formats: `dvbcodec -l` gives details.

Having done the hard work and shipped our beta release, the rest of this
part of the article is dedicated to some closing thoughts.

[h2 Is C++ the Right Tool for the Job?]

My criteria for language selection were somewhat artificial. If I had given
myself a free hand I almost certainly would have been biased towards __python__.
However, having gone the C++ route -- the modern C++ route, even -- it would
seem a good point to step back and review my selection.  

__raymond__ has reservations about C++, which I summarise here:

* By not automating memory management it fails to address C's biggest
shortcoming; and backwards compatibility with C has compromised the language's
design.
   
* Object oriented software design isn't all it's cracked up to be. All too
often it leads to shaky object hierarchies, unnecessary abstractions and code
which is hard to maintain.
      
* C++ is so complex that no one programmer can be expected to know it all.
    
* If C++ really were superior to C, it would now dominate it.

(Incidentally, as already mentioned, __raymond__ is not knocking C++ to promote
C.  His recommendation is to adopt scripted and mixed language solutions.)

To fully address all these points is outside the scope of this article.
Instead I shall consider each in the context of the development of our codec:

* By using standard library containers -- `map`, `vector`, `stack`, `string`
etc -- I have avoided a single direct call to `operator new`. If I've got my
exception handling and my use of __spirit__ right, there should be no leaks.
Regarding C compatibility, I have benefited from the C standard library in a
few places.
      
* The application code (as opposed to the __spirit__ framework code) uses only
a few concrete classes. I have resisted the temptation to make these generic,
or to make them derive from an abstract class. The `RAII` class idiom is
usefully employed. The __spirit__ framework itself has moved with the times: what
was ['implemented with run-time polymorphic classes] is now ['a complete rewrite
... using expression templates and static polymorphism].
    
* Agreed! __spirit__'s fine documentation includes examples which have served
as a basis for my own application. When I deviated from these examples too far
the result was a barely comprehensible torrent of compiler errors. Typeless
programming in a strongly typed language can be tough.
      
[blurb __info__ The "Techniques" section of the __spirit__ documentation 
describes an extraordinary method for obtaining an object's type: ['"... Try 
to compile. Then, the compiler will generate an obnoxious error message ... 
THERE YOU GO! You got its type! I just copy and paste the correct type."] 
Elsewhere, the __spirit__ documentation mentions Dave Abrahams' proposal to 
reuse the `auto` keyword for type deduced variables. See also 
[link refs.colvin Colvin] for a radical take on this issue.]

* C is far more portable. I believe our codec is standards compliant, so maybe
in the long term it will be portable. However, at the moment (September 2004)
the list of compilers which cope with __spirit__ is small. So our codec isn't
truly portable. Not one of the compilers I use at work could cope with this
program. This reflects my experience with C++ over the years: to get the good
stuff, either you wait, or you work around compiler limitations. Bear in mind
too that of two types of compiler bugs -- incorrect error messages, no object
code; no error messages, incorrect object code -- the second is far more
insidious: and the presence of the first naturally leads a
programmer to suspect the existence of the second.

Despite all this, __spirit__ has proven itself flexible, scalable, capable of
expressing grammars clearly and of writing efficient parsers without the need
to step outside C++. Indeed, it could never have been done without C++. I am
sure I will use __spirit__ again.

[h2 Open Source]

The future of Unix is [@http://www.linux.org Linux] is
[@http://www.opensource.org open source]. __raymond__ is passionate about
software quality and argues convincingly that [@http://www.opensource.org open
source] is the best way to deliver the highest quality software. I do not
propose to rehearse these arguments here: __raymond__'s writings are available
both in print form and online. (See, for example 
[@http://www.catb.org/~esr/writings/cathedral-bazaar/ ['The Cathedral and the
Bazaar]]).

What does interest me is that I cannot see how the full power of __spirit__ could
be realised using anything other than a full source code distribution. It's
all done with header files. Maybe with some reworking the implementation could
be delivered in pre-built libraries, multiplied up by the various operating
system, platform, version permutations -- but wouldn't this make it even
harder for compilers to build applications based on __spirit__?

Of course, [@http://www.opensource.org open source] means more than just
access to source: but it's still notable that this style of C++ favours open
source distribution.

[h2 And Finally]

I'm still not sure if it would have been better to write a code generator, to
generate our codec from the section formats.

Maybe I'll try using __spirit__ and C++ to generate a C codec.

[endsect] [/ End of Part two]

[section Part Three]

[h2 Introduction]

Of course I did have a go at re-implementing the codec using the third 
[link implementation_strategies implementation strategy]:

[blurb Devise a code generator which, given a section format, will generate a
program to encode/decode that particular format.]

In fact, my solution using the code generator approach reads in a
['list] of [@sectionformat.cpp section formats] ['at build time].
These formats are then parsed -- ['still at build time] -- and
semantic actions associated with the parser create a
[@sectiondecode.cpp generated C++ file]. This generated file is built
into the actual DVB codec.

[h2 Advantages of the Code Generator Approach]

The main advantages are:

# [#catch_errors_at_build_time] Problems which used to be caught at run time
can now be caught at build time. For example, we can check that our section
formats are syntactically valid at build time.

# Since the section format parsing has been done
at build time, the `dvbcodec` itself runs more efficiently. Without any
deliberate attempt to optimise we have achieved a five-fold speed up -- and I
would also guess a much reduced dynamic memory requirement (I haven't measured
this).

# [#split_up_context] The refactor caused me to split up a 
[link refs.kelly Context] class, which was taking on more responsibility than it should have.
As a result, the [@decodecontext.hpp class] which maintains context during
decoding (things like position in the input data) has been separated from the
[@decodeout.hpp class] which produces the formatted output. This is a better
partitioned and more flexible solution.

A common advantage -- of reducing the amount boiler-plate code to be
written and maintained -- was, in this case, absent. In fact, there is
very slightly /more/ code in the generated `dvbcodec`.

[h2 Disadvantages of the Code Generator Approach]

The generated code approach has some very real disadvantages:

# The codec worked just fine as it was: any refactor is risky, even
with [link downloads.test_suite unit tests] in place.

# The generator approach puts more strain on the build system. Of course, we
generally prefer to work harder at build time if it gives us more 
[link catch_errors_at_build_time confidence] about what will happen at run 
time -- but this is still an important consideration. Some integrated development 
environments don't accomodate custom builds well.

# Writing code to write code is a form of metaprogramming: what might once
have been achieved directly now requires thinking on a different level. This
is particularly tricky when -- as in this case -- C++ is being used to write
C++. 

To illustrate this third point, compare the following /direct/ lines of C++,
used to produce formatted output: 

    std::string const value =
        context.readFieldValue(field_name,
                               decodeUnsignedLong(bitwidth));

    context.decodeOut()
        << context.indent()
        << field_name << " "
        << bitwidth
        << " = 0x" << value << "\n";

with the lines used to /generate/ the equivalent functionality:

    cpp_
        << indent()
        << "context.decodeOut() << context.indent() << "
        << quote(field_name
                + " "
                + bitwidth 
                + " = 0x")
        << " << context.readFieldValue("
        << quote(field_name) + ", "
        << decodeUnsignedLong(bitwidth) << ") << \"\\n\";\n";

Now you know why I had to
[link split_up_context separate decode context from decode output]
for the generated version. You'll also realise why it's more common
to use a language like __python__ -- with its handy support for 
triple quoted strings, raw strings and so on -- to generate C++.

One common disadvantage -- that the generated code isn't very nice to
look at -- was, in this case, absent. I was genuinely surprised and
delighted by the clarity of the generated [@sectiondecode.cpp section
decoder]. The extract below compares nicely with the 
[link program_association_section PAT section syntax].

    // GENERATED FILE. DO NOT EDIT.
    // Generated by: dvbcodecgenerator 
    // On: Nov 25 2004
    /**
     * Copyright (c) 2004, Thomas Guest. All rights reserved.
     * @file
     * @brief Generated section decoders.
     */    

    /**
     * @brief Generated program_association_section decoder
     */
    void
    decode_program_association_section(DecodeOut & out)
    {
        out.putSectionName("program_association_section()");
        {
            out.enterBlock();
            out.putField("table_id", 8);
            out.putField("section_syntax_indicator", 1);
            out.putField("'0'", 1);
            out.putField("reserved", 2);
            out.putField("section_length", 12);
            out.putField("transport_stream_id", 16);
            out.putField("reserved", 2);
            out.putField("version_number", 5);
            out.putField("current_next_indicator", 1);
            out.putField("section_number", 8);
            out.putField("last_section_number", 8);
            out.putLoopControl("for (i=0; i<N; i++)");
            out.enterBlock();
            while(!out.testLoopExit())
            {
                out.putField("program_number", 16);
                out.putField("reserved", 3);
                if (out.putIf("program_number", "==", '0'))
                {
                    out.enterBlock();
                    out.putField("network_PID", 13);
                    out.leaveBlock();
                }
                else if (out.putElse())
                {
                    out.enterBlock();
                    out.putField("program_map_PID", 13);
                    out.leaveBlock();
                }
            }
            out.putField("CRC_32", 32);
            out.leaveBlock();
        }
    }

[h2 On Balance]

On balance, I prefer the version of `dvbcodec` based on the generated section
decoder. The big win is that more errors can be 
[link catch_errors_at_build_time caught at build time]. Either way, it was
well worth exploring both options.

[endsect] [/ End of Part Three]

[section Downloads]

[h2 Introduction]

This page provides links to the various downloads which accompany
this article.

[h2 Test Suite]

The test suite developed during the [link part_one.more_details first part] of
this article can be found at:

[:[@testsuite-1.0.zip]]

[h2 DVB Codec 0.2]

The source distribution developed during the 
[link ship_happens second part] of this article can be found at:

[:[@dvbcodec-0.2.zip]]

[h2 DVB Codec 1.0]

Version 1.0 of the DVB codec, as described in [link part_three.introduction the  
third part] of this article, can be found at:

[:[@dvbcodec-1.0.zip]]

The generated [@http://www.doxygen.org Doxygen] HTML documentation can be found
[@doxygen/html/index.html here.]

[endsect] [/ End of Download]
    
[section:refs References]

[h3 ACCU]

Quoting from the [@http://www.accu.org homepage] 

[blurb "The ACCU is a non-profit organisation devoted to
professionalism in programming at all levels. Although primarily focussed on C
and C++, we also have interests in Java, C# and Python."]


[h3 Alexandrescu] 

I borrowed the phrase /Ship Happens/ from Andrei Alexandrescu's
[@http://www.moderncppdesign.com/main.html homepage]. It's funny because it's
true.

[h3 Antonsen] 

['Stream-Based Parsing in C++], Frank Antonsen,
[link refs.overload Overload] 56, August 2003
 
[h3 Boost] 

[@http://www.boost.org]

[h3 Colvin]

Greg Colvin, [@http://www.artima.com/cppsource/spiritofc.html ['In the Spirit of C]]

[h3 ETSI EN 300 468]

ETSI EN 300468 Digital Video Broadcasting (__dvb__); Specification for Service
Information (SI) in __dvb__ systems

[h3 Heinzmann] 

S. Heinzmann, "The Tale of a Struggling Template Programmer", 
[link refs.overload Overload 61], June 2004

[h3 ISO/IEC 13818-1] 

INFORMATION TECHNOLOGY - GENERIC CODING OF MOVING PICTURES
AND ASSOCIATED AUDIO: SYSTEMS Recommendation H.222.0 ISO/IEC 13818-1


[h3 Kelly]

['The Encapsulate Context Pattern], [@http://www.allankelly.net Allan
Kelly], [link refs.overload Overload 63], October 2004

[h3 Overload]

Overload is an [link refs.accu ACCU] publication.

[h3 PLY] 

[@http://systems.cs.uchicago.edu/ply/]

[h3 Postel] 

The canonical form of Postel's prescription, according to
[@http://www.catb.org/~esr/jargon/ the jargon file] is: ['Be liberal in what
you accept, and conservative in what you send.]

[h3 Quickbook]

The [link refs.quickbook Quickbook] documentation tool comes with the
__spirit__ source distribution. It is an excellent example of what __spirit__
can do, and a powerful tool in its own right.

[h3 Raymond]

* ['The Art of UNIX Programming], Addison-Wesley 0-13-142901-9, Eric S. Raymond

* [@http://www.catb.org/~esr/writings/cathedral-bazaar/ ['The Cathedral and the
Bazaar]], Eric S. Raymond   

[h3 XP] 

Extreme Programming, [@http://www.extremeprogramming.org]


[endsect] [/ End References]

[section Credits]

This article originally appeared in the [@http://www.accu.org ACCU's] 
[link refs.overload Overload] journal, and I would like to thank the 
[link refs.overload Overload] editorial team for their feedback and assistance.

This revised version has been published with the considerable help of
the [link refs.quickbook Quickbook] documentation tool, which allows you to
generate [@http://www.boost.org/doc/html/boostbook.html BoostBook]
documentation from a WikiWiki style [@dvbcodec-doc.qbk plain text source
file.] I would also like to thank [@http://www.basemetal.co.uk Nik Stoltzman]
for his help with the graphics.

The accompanying source code was developed using the __gnu__ emacs
integrated development environment (__gnu__ emacs, __gnu__ make, GCC,
find, grep, etc), [@http://www.jasspa.com ['JASSPA Microemacs]] (for
its superb text mode and binary editor), all running on the -- sorry
[link refs.raymond Eric], thanks [@http://www.cygwin.org
Cygwin] -- Microsoft Windows operating system.

[endsect] [/ End Credits]
